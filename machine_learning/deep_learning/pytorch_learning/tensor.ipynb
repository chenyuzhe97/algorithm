{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 导入包"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch中常用的创建张量的方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个tensor\n",
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "#获得张量a的形状，是一个元组\n",
    "print(a.size())\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[6.6280e-10, 6.5920e-10, 2.6082e+20],\n",
      "        [1.0721e-08, 5.2299e+22, 6.7945e-07]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.empty(2, 3)\n",
    "print(x.size())\n",
    "#多次运行可以看到，每次的x都是不一样的，因为未初始化\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#运用a参数后，此时y和a一样了\n",
    "y = torch.empty(2,3,out = a)\n",
    "print(y.size())\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个size和y一样的未初始化张量\n",
    "empty_like = torch.empty_like(y)\n",
    "print(empty_like.size())\n",
    "print(empty_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "- torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
    "    - 返回一个未初始化的张量，张量大小由参数size定义。\n",
    "    - 参数说明：\n",
    "        size(int…)：是一个用于定义输出的张量的形状的整形序列，也可以是list或者tuple。\n",
    "        out(Tensor，可选)：要求的值为张量，默认为none。也可以令out为一个具体张量a（a的shape与参数size相同），这样输出的张量就会和a一样。上面的例子可以看出。\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是torch.set_default_tensor_type的值。可以通过这个dtype参数来改变输出的张量的数据类型。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为torch.strided。torch.strided代表密集型张量，是最常见的内存布局；每个strided张量都关联一个torch.Storage，torch.Storage保存着strided张量的数据。\n",
    "        device(torch.device,可选):创建的张量存放的device。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。\n",
    "- torch.empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
    "    - 返回一个与input形状一样的使用未初始化值填满的tensor，相当于torch.empty(input.size(), dtype=input.dtype, layout=input.layout,\n",
    "    - 参数说明：\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是torch.set_default_tensor_type的值。可以通过这个dtype参数来改变输出的张量的数据类型。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为torch.strided。torch.strided代表密集型张量，是最常见的内存布局；每个strided张量都关联一个torch.Storage，torch.Storage保存着strided张量的数据。\n",
    "        device(torch.device,可选):创建的张量存放的device。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。\n",
    "        memory_format(torch.memory_format, 可选): 期望返回张量的保存类型，默认为torch.preserve_format。torch.memory类型用于保存torch.Tensor的储存格式。torch.preserve_format是保留输入张量的内存格式，用在clone这样的函数中。如果输入张量是分配在稠密不重叠的内存中，那么输出张量的stride与输入相同。否则，输出的strides使用torch.contiguous_format。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0559, 0.8401, 0.7197],\n",
      "        [0.7270, 0.6326, 0.8509]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个随机的初始化矩阵\n",
    "x = torch.rand(2,3)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "    - 返回服从均匀分布的初始化后的张量，张量大小由参数size定义。\n",
    "    - 参数说明：\n",
    "        size(int…)：是一个用于定义输出的张量的形状的整形序列，也可以是list或者tuple。\n",
    "        out(Tensor，可选)：要求的值为张量，默认为none。也可以令out为一个具体张量a（a的shape与参数size相同），这样输出的张量就会和a一样。\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是torch.set_default_tensor_type的值。可以通过这个dtype参数来改变输出的张量的数据类型。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为torch.strided。torch.strided代表密集型张量，是最常见的内存布局；每个strided张量都关联一个torch.Storage，torch.Storage保存着strided张量的数据。\n",
    "        device(torch.device,可选):创建的张量存放的device。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个全是0的矩阵，并且令数据类型为torch.long\n",
    "x = torch.zeros(2,3,dtype = torch.long)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%创建一个全是0的矩阵，并且令数据类型为torch.long\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "    - 返回一个值全为0的张量，张量大小由参数size定义，值类型由torch.dtype定义。\n",
    "    - 参数说明：\n",
    "        size(int…)：是一个用于定义输出的张量的形状的整形序列，也可以是list或者tuple。\n",
    "        out(Tensor，可选)：要求的值为张量，默认为none。也可以令out为一个具体张量a（a的shape与参数size相同），这样输出的张量就会和a一样。\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是torch.set_default_tensor_type的值。可以通过这个dtype参数来改变输出的张量的数据类型。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为torch.strided。torch.strided代表密集型张量，是最常见的内存布局；每个strided张量都关联一个torch.Storage，torch.Storage保存着strided张量的数据。\n",
    "        device(torch.device,可选):创建的张量存放的device。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。\n",
    "        '''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[0.6288, 0.0157, 0.2382],\n",
      "        [0.2832, 0.6589, 0.8351]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个全是1的张量，并在此基础上创建新的张量\n",
    "#创建一个全是1的矩阵\n",
    "x = x.new_ones(2,3,dtype = torch.double)\n",
    "print(x)\n",
    "#重新设定了dtype\n",
    "x = torch.rand_like(x,dtype = torch.float)\n",
    "#可以看到形状一样，但数据类型不同了。\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], dtype=torch.int32)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor((),dtype = torch.int32)\n",
    "print(x)\n",
    "x = x.new_ones(2,3)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
    "    - 返回一个值全为1的张量，张量的size和dtype与tensor相同。\n",
    "    - 参数说明：\n",
    "        size(int…)：是一个用于定义输出的张量的形状的整形序列，也可以是list或者tuple。\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是None。若为None，则为与tensor相同的torch.dtype。\n",
    "        device(torch.device,可选):创建的张量存放的device，默认与input相同。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。\n",
    "        '''\n",
    "- torch.randn_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
    "    - 返回一个和input相同size的张量，这个张量由均值为0，方差为1的标准正态分布填充。\n",
    "    - 参数说明：\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是None。若为None，则为与input相同的torch.dtype。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为input的分布。\n",
    "        device(torch.device, 可选):创建的张量存放的device,默认与input相同。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。\n",
    "        memory_format(torch.memory_format, 可选): 期望返回张量的保存类型，默认为torch.preserve_format。torch.memory类型用于保存torch.Tensor的储存格式。torch.preserve_format是保留输入张量的内存格式，用在clone这样的函数中。如果输入张量是分配在稠密不重叠的内存中，那么输出张量的stride与输入相同。否则，输出的strides使用torch.contiguous_format。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个值全为3.1416的5*3的矩阵\n",
    "x=torch.full((5, 3), 3.1416)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
    "    - 返回一个未初始化的张量，张量大小由参数size定义。\n",
    "    - 参数说明：\n",
    "        size(int…)：是一个用于定义输出的张量的形状的整形序列，也可以是list或者turple。\n",
    "        out(Tensor，可选)：要求的值为张量，默认为none。也可以令out为一个具体张量a（a的shape与参数size相同），这样输出的张量就会和a一样。上面的例子可以看出。\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是torch.set_default_tensor_type的值。可以通过这个dtype参数来改变输出的张量的数据类型。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为torch.strided。torch.strided代表密集型张量，是最常见的内存布局；每个strided张量都关联一个torch.Storage，torch.Storage保存着strided张量的数据。\n",
    "        device(torch.device,可选):创建的张量存放的device。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个维度为4，对角线位置为1，其他位置全为0的二维张量。\n",
    "eye = torch.eye(4)\n",
    "print(eye.size())#获得张量eye的形状，是一个元组\n",
    "print(eye)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "    - 返回一个行数为n，列数为m，对角线上为1而其他位置为0的二维张量。\n",
    "    - 参数说明：\n",
    "        n(int):要求输入一个整数，表示行数。\n",
    "        m(int):要求输入一个整数，表示列数，默认为None。如果为None，则m的值为n。\n",
    "        out(Tensor，可选)：要求的值为张量，默认为none。也可以令out为一个具体张量a（a的shape与参数size相同），这样输出的张量就会和a一样。\n",
    "        dtype(torch.dtype，可选): 要求的值的类型是torch.dtype，默认值是torch.set_default_tensor_type的值。可以通过这个dtype参数来改变输出的张量的数据类型。\n",
    "        layout(torch.layout，可选)：torch.layput表示torch.Tensor内存布局的对象。这个参数表示你希望返回的张量的内存布局类型，默认为torch.strided。torch.strided代表密集型张量，是最常见的内存布局；每个strided张量都关联一个torch.Storage，torch.Storage保存着strided张量的数据。\n",
    "        device(torch.device,可选):创建的张量存放的device。\n",
    "        requires_grad(bool，可选)：要求的值为bool类型，默认为False。若为False则反向传播时不会对这个节点求导。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 基本运算操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2093, 0.4807, 0.3659],\n",
      "        [0.8315, 0.0009, 0.7417],\n",
      "        [0.7746, 0.6414, 0.6804],\n",
      "        [0.3440, 0.8610, 0.6680],\n",
      "        [0.8730, 0.6988, 0.8227]])\n",
      "tensor([[0.7758, 0.9211, 0.1448],\n",
      "        [0.3644, 0.9201, 0.1888],\n",
      "        [0.0368, 0.4946, 0.9918],\n",
      "        [0.0146, 0.3755, 0.0517],\n",
      "        [0.6742, 0.9276, 0.6756]])\n",
      "tensor([[0.9851, 1.4018, 0.5107],\n",
      "        [1.1959, 0.9210, 0.9305],\n",
      "        [0.8115, 1.1360, 1.6721],\n",
      "        [0.3586, 1.2365, 0.7197],\n",
      "        [1.5472, 1.6263, 1.4983]])\n",
      "tensor([[0.9851, 1.4018, 0.5107],\n",
      "        [1.1959, 0.9210, 0.9305],\n",
      "        [0.8115, 1.1360, 1.6721],\n",
      "        [0.3586, 1.2365, 0.7197],\n",
      "        [1.5472, 1.6263, 1.4983]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(5,3)\n",
    "b = torch.rand(5,3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(a + b)\n",
    "print(torch.add(a, b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0194e-38, 8.4490e-39, 1.0469e-38],\n",
      "        [9.3674e-39, 9.9184e-39, 8.7245e-39],\n",
      "        [9.2755e-39, 8.9082e-39, 9.9184e-39],\n",
      "        [8.4490e-39, 9.6429e-39, 1.0653e-38],\n",
      "        [1.0469e-38, 4.2246e-39, 1.0378e-38]])\n",
      "tensor([[0.9851, 1.4018, 0.5107],\n",
      "        [1.1959, 0.9210, 0.9305],\n",
      "        [0.8115, 1.1360, 1.6721],\n",
      "        [0.3586, 1.2365, 0.7197],\n",
      "        [1.5472, 1.6263, 1.4983]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "print(result)\n",
    "#out参数提供一个输出张量作为加法的结果\n",
    "torch.add(a, b, out = result)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}